from langchain_ollama import ChatOllama
from langchain.agents import initialize_agent
try:
    # LC 0.3.x
    from langchain.agents import AgentType
    AGENT_TYPE = AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION
except Exception:
    # fallback na nazwÄ™ stringowÄ…
    AGENT_TYPE = "structured-chat-zero-shot-react-description"

from langchain.tools import StructuredTool
import os
import traceback

# ---------- NARZÄ˜DZIA (multi-input) ----------

def write_file(filepath: str, contents: str) -> str:
    """Zapisz (utwÃ³rz/nadpisz) plik na dysku."""
    parent = os.path.dirname(filepath)
    if parent:
        os.makedirs(parent, exist_ok=True)
    with open(filepath, "w", encoding="utf-8") as f:
        f.write(contents)
    return f"âœ… Zapisano do {filepath} ({len(contents)} bajtÃ³w)"

def read_file(filepath: str) -> str:
    """Odczytaj zawartoÅ›Ä‡ pliku."""
    if not os.path.exists(filepath):
        return f"âŒ Plik {filepath} nie istnieje"
    with open(filepath, "r", encoding="utf-8") as f:
        return f.read()

tools = [
    StructuredTool.from_function(
        func=write_file,
        name="write_file",
        description=(
            "Zapisz/utwÃ³rz plik. Argumenty: "
            "filepath (Å›cieÅ¼ka, np. './src/main.py'), "
            "contents (peÅ‚na treÅ›Ä‡ pliku)."
        ),
    ),
    StructuredTool.from_function(
        func=read_file,
        name="read_file",
        description=(
            "Odczytaj plik. Argumenty: "
            "filepath (Å›cieÅ¼ka, np. './src/main.py')."
        ),
    ),
]

# ---------- MODEL ----------
llm = ChatOllama(
    model="deepcoder:14b",
    temperature=0.2,
    num_ctx=8192,
)

# ---------- AGENT (Structured Chat) ----------
SYSTEM_MSG = (
    "JesteÅ› asystentem-koderem z narzÄ™dziami plikowymi. "
    "Gdy uÅ¼ytkownik prosi o stworzenie/edycjÄ™/odczyt pliku, "
    "UÅ»YJ odpowiednio write_file lub read_file, przekazujÄ…c wszystkie argumenty. "
    "Nie pytaj o format â€“ sam zdecyduj i dziaÅ‚aj."
)

agent = initialize_agent(
    tools=tools,
    llm=llm,
    agent=AGENT_TYPE,              # <â€” obsÅ‚uga multi-input tools
    verbose=True,
    handle_parsing_errors=True,
    agent_kwargs={"system_message": SYSTEM_MSG},
)

# ---------- REPL ----------
if __name__ == "__main__":
    print("ğŸ¤– DeepCoder REPL (Structured Chat). Wpisz 'exit' aby wyjÅ›Ä‡.\n")
    while True:
        try:
            cmd = input("ğŸ“> ").strip()
            if cmd.lower() in ("exit", "quit"):
                print("ğŸ‘‹ Do zobaczenia!")
                break

            # W LC 0.3.x unikaj .run(); uÅ¼ywaj .invoke({"input": ...})
            result = agent.invoke({"input": cmd})
            output = result.get("output", result)
            print(f"\nğŸ’¡ OdpowiedÅº:\n{output}\n{'-'*60}\n")

        except KeyboardInterrupt:
            print("\nğŸ‘‹ Przerwano.")
            break
        except Exception as e:
            print("âŒ BÅ‚Ä…d:", e)
            traceback.print_exc()
