models:
  # Primary development model
  deepcoder:
    name: "DeepCoder 14B"
    model_id: "deepcoder:14b"
    provider: "ollama"
    description: "Advanced AI coding assistant specialized for software development (Primary Model)"
    capabilities:
      coding: true
      general_qa: true
      file_operations: true
      streaming: true
    parameters:
      temperature: 0.1
      num_ctx: 16384
      num_predict: 2048
      repeat_penalty: 1.1
      top_k: 40
      top_p: 0.9
    tools:
      - file_ops
      - system
      - project
      - code_execution
      - web
    system_message: |
      You are DeepCoder, an advanced AI coding assistant with comprehensive capabilities similar to GitHub Copilot.
      
      CORE PRINCIPLES:
      1. Always execute actions immediately when requested - don't ask for permission
      2. Provide complete, working code solutions
      3. Use the available tools to perform file operations, run commands, and manage projects
      4. Focus on practical, actionable solutions
      5. Be concise but thorough in explanations

  # Large Llama models
  llama3_3_70b_q2:
    name: "Llama 3.3 70B (Q2_K)"
    model_id: "llama3.3:70b-instruct-q2_K"
    provider: "ollama"
    description: "Large Llama model with 70B parameters, Q2_K quantization (26GB)"
    capabilities:
      coding: true
      general_qa: true
      file_operations: false
      streaming: true
    parameters:
      temperature: 0.7
      num_ctx: 8192
      num_predict: 1024
    tools:
      - system
      - web
    
  llama3_3_70b_q3:
    name: "Llama 3.3 70B (Q3_K_M)"
    model_id: "llama3.3:70b-instruct-q3_K_M"
    provider: "ollama"
    description: "Large Llama model with 70B parameters, Q3_K_M quantization (34GB)"
    capabilities:
      coding: true
      general_qa: true
      file_operations: false
      streaming: true
    parameters:
      temperature: 0.7
      num_ctx: 8192
      num_predict: 1024
    tools:
      - system
      - web

  # Qwen models
  qwen2_5_3b:
    name: "Qwen 2.5 3B Instruct"
    model_id: "qwen2.5:3b-instruct-q4_K_M"
    provider: "ollama"
    description: "Compact Qwen model with strong multilingual capabilities (1.9GB)"
    capabilities:
      coding: true
      general_qa: true
      file_operations: true
      streaming: true
    parameters:
      temperature: 0.3
      num_ctx: 8192
      num_predict: 1024
    tools:
      - file_ops
      - system
      - project

  qwen2_5_7b:
    name: "Qwen 2.5 7B Instruct"
    model_id: "qwen2.5:7b-instruct-q4_K_M"
    provider: "ollama"
    description: "Mid-size Qwen model with excellent reasoning (4.7GB)"
    capabilities:
      coding: true
      general_qa: true
      file_operations: true
      streaming: true
    parameters:
      temperature: 0.3
      num_ctx: 12288
      num_predict: 1536
    tools:
      - file_ops
      - system
      - project
      - code_execution

  qwen2_5_coder_7b:
    name: "Qwen 2.5 Coder 7B"
    model_id: "qwen2.5-coder:7b"
    provider: "ollama"
    description: "Specialized Qwen model for coding tasks (4.7GB)"
    capabilities:
      coding: true
      general_qa: false
      file_operations: true
      streaming: true
    parameters:
      temperature: 0.1
      num_ctx: 16384
      num_predict: 2048
    tools:
      - file_ops
      - project
      - code_execution

  # Gemma model
  gemma_7b:
    name: "Gemma 7B Instruct"
    model_id: "gemma:7b-instruct-q4_K_M"
    provider: "ollama"
    description: "Google's efficient Gemma model (5.5GB)"
    capabilities:
      coding: true
      general_qa: true
      file_operations: false
      streaming: true
    parameters:
      temperature: 0.5
      num_ctx: 8192
      num_predict: 1024
    tools:
      - system
      - web

  # CodeLlama models
  codellama_13b:
    name: "CodeLlama 13B Instruct"
    model_id: "codellama:13b-instruct"
    provider: "ollama"
    description: "Meta's specialized coding model (7.4GB)"
    capabilities:
      coding: true
      general_qa: false
      file_operations: true
      streaming: true
    parameters:
      temperature: 0.1
      num_ctx: 16384
      num_predict: 2048
    tools:
      - file_ops
      - project
      - code_execution

  codellama_13b_q4:
    name: "CodeLlama 13B Instruct (Q4_K_M)"
    model_id: "codellama:13b-instruct-q4_K_M"
    provider: "ollama"
    description: "Meta's specialized coding model, Q4_K_M quantization (7.9GB)"
    capabilities:
      coding: true
      general_qa: false
      file_operations: true
      streaming: true
    parameters:
      temperature: 0.1
      num_ctx: 16384
      num_predict: 2048
    tools:
      - file_ops
      - project
      - code_execution

  # Mistral models
  mistral_7b:
    name: "Mistral 7B Instruct"
    model_id: "mistral:7b-instruct"
    provider: "ollama"
    description: "Mistral AI's efficient 7B model (4.4GB)"
    capabilities:
      coding: true
      general_qa: true
      file_operations: false
      streaming: true
    parameters:
      temperature: 0.6
      num_ctx: 8192
      num_predict: 1024
    tools:
      - system
      - web

  mistral_7b_q4:
    name: "Mistral 7B Instruct (Q4_K_M)"
    model_id: "mistral:7b-instruct-q4_K_M"
    provider: "ollama"
    description: "Mistral AI's efficient 7B model, Q4_K_M quantization (4.4GB)"
    capabilities:
      coding: true
      general_qa: true
      file_operations: false
      streaming: true
    parameters:
      temperature: 0.6
      num_ctx: 8192
      num_predict: 1024
    tools:
      - system
      - web

  # DeepSeek Coder models
  deepseek_coder_6_7b:
    name: "DeepSeek Coder 6.7B"
    model_id: "deepseek-coder:6.7b"
    provider: "ollama"
    description: "DeepSeek's specialized coding model (3.8GB)"
    capabilities:
      coding: true
      general_qa: false
      file_operations: true
      streaming: true
    parameters:
      temperature: 0.1
      num_ctx: 16384
      num_predict: 2048
    tools:
      - file_ops
      - project
      - code_execution

  deepseek_coder_v2_16b:
    name: "DeepSeek Coder V2 16B Lite"
    model_id: "deepseek-coder-v2:16b-lite-instruct-q4_K_M"
    provider: "ollama"
    description: "DeepSeek's advanced coding model V2 (10GB)"
    capabilities:
      coding: true
      general_qa: false
      file_operations: true
      streaming: true
    parameters:
      temperature: 0.1
      num_ctx: 16384
      num_predict: 2048
    tools:
      - file_ops
      - project
      - code_execution

  # Compact models
  phi3_mini:
    name: "Phi-3 Mini"
    model_id: "phi3:mini"
    provider: "ollama"
    description: "Microsoft's compact and efficient model (2.2GB)"
    capabilities:
      coding: true
      general_qa: true
      file_operations: false
      streaming: true
    parameters:
      temperature: 0.4
      num_ctx: 4096
      num_predict: 512
    tools:
      - system

  tinyllama:
    name: "TinyLlama"
    model_id: "tinyllama:latest"
    provider: "ollama"
    description: "Extremely compact model for testing (637MB)"
    capabilities:
      coding: false
      general_qa: true
      file_operations: false
      streaming: true
    parameters:
      temperature: 0.8
      num_ctx: 2048
      num_predict: 256
    tools:
      - system
