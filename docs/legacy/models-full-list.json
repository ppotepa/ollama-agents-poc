{
  "gpt-oss": {
    "Tag / filename": "gpt-oss",
    "Sizes / variants": "20b, 120b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "Yes",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "OpenAI open-weight models via Ollama; strong reasoning.",
    "How to pull (example)": "ollama pull gpt-oss:20b"
  },
  "deepseek-r1": {
    "Tag / filename": "deepseek-r1",
    "Sizes / variants": "1.5b, 7b, 8b, 14b, 32b, 70b, 671b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "Yes",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Reasoning-first family; distilled variants available.",
    "How to pull (example)": "ollama pull deepseek-r1:7b"
  },
  "qwen3": {
    "Tag / filename": "qwen3",
    "Sizes / variants": "0.6b, 1.7b, 4b, 8b, 14b, 30b, 32b, 235b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "Yes",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Latest dense and MoE; strong multilingual.",
    "How to pull (example)": "ollama pull qwen3:8b"
  },
  "llama3.1": {
    "Tag / filename": "llama3.1",
    "Sizes / variants": "8b, 70b, 405b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "128K",
    "Example disk size (latest)": "4.9GB (8B, example)",
    "Notes": "Meta Llama 3.1 instruction-tuned; long context.",
    "How to pull (example)": "ollama pull llama3.1:8b"
  },
  "llama3.2": {
    "Tag / filename": "llama3.2",
    "Sizes / variants": "1b, 3b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Small multilingual text-only.",
    "How to pull (example)": "ollama pull llama3.2:3b"
  },
  "mistral": {
    "Tag / filename": "mistral",
    "Sizes / variants": "7b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Mistral 7B v0.3.",
    "How to pull (example)": "ollama pull mistral"
  },
  "qwen2.5": {
    "Tag / filename": "qwen2.5",
    "Sizes / variants": "0.5b, 1.5b, 3b, 7b, 14b, 32b, 72b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "up to 128K",
    "Example disk size (latest)": "",
    "Notes": "Multilingual; long context.",
    "How to pull (example)": "ollama pull qwen2.5:7b"
  },
  "qwen2.5-coder": {
    "Tag / filename": "qwen2.5-coder",
    "Sizes / variants": "0.5b, 1.5b, 3b, 7b, 14b, 32b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Code‑specialized series.",
    "How to pull (example)": "ollama pull qwen2.5-coder:7b"
  },
  "qwen2": {
    "Tag / filename": "qwen2",
    "Sizes / variants": "0.5b, 1.5b, 7b, 72b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Earlier Qwen family (still available).",
    "How to pull (example)": "ollama pull qwen2:7b"
  },
  "mistral-nemo": {
    "Tag / filename": "mistral-nemo",
    "Sizes / variants": "12b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "up to 128K",
    "Example disk size (latest)": "",
    "Notes": "Mistral x NVIDIA collab model.",
    "How to pull (example)": "ollama pull mistral-nemo"
  },
  "llama3.3": {
    "Tag / filename": "llama3.3",
    "Sizes / variants": "70b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "New SoTA 70B, comparable to Llama 3.1 405B.",
    "How to pull (example)": "ollama pull llama3.3"
  },
  "qwq (Qwen reasoning)": {
    "Tag / filename": "qwq",
    "Sizes / variants": "32b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No (reasoner)",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Reasoning‑focused model in Qwen family.",
    "How to pull (example)": "ollama pull qwq:32b"
  },
  "mistral-small3.1": {
    "Tag / filename": "mistral-small3.1",
    "Sizes / variants": "24b",
    "Supports Tools": "Yes",
    "Supports Vision": "Yes",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "up to 128K",
    "Example disk size (latest)": "",
    "Notes": "Adds vision vs Small 3; improved long context.",
    "How to pull (example)": "ollama pull mistral-small3.1"
  },
  "mistral-small3.2": {
    "Tag / filename": "mistral-small3.2",
    "Sizes / variants": "24b",
    "Supports Tools": "Yes",
    "Supports Vision": "Yes",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Function calling and instruction following improved.",
    "How to pull (example)": "ollama pull mistral-small3.2"
  },
  "mixtral": {
    "Tag / filename": "mixtral",
    "Sizes / variants": "8x7b, 8x22b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Mixture‑of‑Experts by Mistral.",
    "How to pull (example)": "ollama pull mixtral:8x7b"
  },
  "mistral-large": {
    "Tag / filename": "mistral-large",
    "Sizes / variants": "123b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "128K",
    "Example disk size (latest)": "",
    "Notes": "Flagship large model.",
    "How to pull (example)": "ollama pull mistral-large"
  },
  "granite3.3": {
    "Tag / filename": "granite3.3",
    "Sizes / variants": "2b, 8b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "128K",
    "Example disk size (latest)": "~4.9GB (8B, Q4)",
    "Notes": "IBM Granite 3.3; improved reasoning/instruction.",
    "How to pull (example)": "ollama pull granite3.3:8b"
  },
  "granite3.2": {
    "Tag / filename": "granite3.2",
    "Sizes / variants": "2b, 8b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "Yes (\"thinking\" fine‑tuned)",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Long‑context, thinking‑tuned.",
    "How to pull (example)": "ollama pull granite3.2:8b"
  },
  "granite3.2-vision": {
    "Tag / filename": "granite3.2-vision",
    "Sizes / variants": "2b",
    "Supports Tools": "Yes",
    "Supports Vision": "Yes",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Doc understanding & extraction.",
    "How to pull (example)": "ollama pull granite3.2-vision"
  },
  "granite3.1-dense": {
    "Tag / filename": "granite3.1-dense",
    "Sizes / variants": "2b, 8b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Dense text‑only Granite 3.1.",
    "How to pull (example)": "ollama pull granite3.1-dense:8b"
  },
  "granite3-dense": {
    "Tag / filename": "granite3-dense",
    "Sizes / variants": "2b, 8b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Granite 3 dense; RAG/tool support.",
    "How to pull (example)": "ollama pull granite3-dense:8b"
  },
  "granite3.1-moe": {
    "Tag / filename": "granite3.1-moe",
    "Sizes / variants": "1b, 3b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "IBM Granite MoE (low‑latency).",
    "How to pull (example)": "ollama pull granite3.1-moe:3b"
  },
  "granite3-moe": {
    "Tag / filename": "granite3-moe",
    "Sizes / variants": "1b, 3b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "IBM Granite MoE family.",
    "How to pull (example)": "ollama pull granite3-moe:3b"
  },
  "hermes3": {
    "Tag / filename": "hermes3",
    "Sizes / variants": "3b, 8b, 70b, 405b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Nous Research Hermes 3.",
    "How to pull (example)": "ollama pull hermes3:8b"
  },
  "magistral": {
    "Tag / filename": "magistral",
    "Sizes / variants": "24b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "Yes",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Small efficient reasoning model.",
    "How to pull (example)": "ollama pull magistral"
  },
  "cogito": {
    "Tag / filename": "cogito",
    "Sizes / variants": "3b, 8b, 14b, 32b, 70b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Hybrid reasoning models by Deep Cogito.",
    "How to pull (example)": "ollama pull cogito:14b"
  },
  "devstral": {
    "Tag / filename": "devstral",
    "Sizes / variants": "24b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Coding‑agent oriented.",
    "How to pull (example)": "ollama pull devstral"
  },
  "phi4-mini": {
    "Tag / filename": "phi4-mini",
    "Sizes / variants": "3.8b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Function‑calling support.",
    "How to pull (example)": "ollama pull phi4-mini"
  },
  "smollm2": {
    "Tag / filename": "smollm2",
    "Sizes / variants": "135m, 360m, 1.7b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Compact LLMs for edge/CPU.",
    "How to pull (example)": "ollama pull smollm2:1.7b"
  },
  "mistral-small": {
    "Tag / filename": "mistral-small",
    "Sizes / variants": "22b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Older Small (text‑only).",
    "How to pull (example)": "ollama pull mistral-small"
  },
  "mixtral (Groq tool‑use)": {
    "Tag / filename": "llama3-groq-tool-use",
    "Sizes / variants": "8b, 70b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "8K on some tags",
    "Example disk size (latest)": "~4.7GB (8B example)",
    "Notes": "Groq instruction models for tool use.",
    "How to pull (example)": "ollama pull llama3-groq-tool-use:8b"
  },
  "aya-expanse": {
    "Tag / filename": "aya-expanse",
    "Sizes / variants": "8b, 32b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Cohere For AI multilingual models.",
    "How to pull (example)": "ollama pull aya-expanse:32b"
  },
  "command-r": {
    "Tag / filename": "command-r",
    "Sizes / variants": "35b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "128K",
    "Example disk size (latest)": "",
    "Notes": "Cohere RAG / tools‑optimized.",
    "How to pull (example)": "ollama pull command-r"
  },
  "command-r-plus": {
    "Tag / filename": "command-r-plus",
    "Sizes / variants": "104b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Cohere enterprise LLM.",
    "How to pull (example)": "ollama pull command-r-plus"
  },
  "command-a": {
    "Tag / filename": "command-a",
    "Sizes / variants": "111b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Cohere 111B enterprise model.",
    "How to pull (example)": "ollama pull command-a"
  },
  "command-r7b": {
    "Tag / filename": "command-r7b",
    "Sizes / variants": "7b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Lightweight Command R variant.",
    "How to pull (example)": "ollama pull command-r7b"
  },
  "command-r7b-arabic": {
    "Tag / filename": "command-r7b-arabic",
    "Sizes / variants": "7b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Arabic‑optimized Command R7B.",
    "How to pull (example)": "ollama pull command-r7b-arabic"
  },
  "firefunction-v2": {
    "Tag / filename": "firefunction-v2",
    "Sizes / variants": "70b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Function‑calling model based on Llama 3.",
    "How to pull (example)": "ollama pull firefunction-v2:70b"
  },
  "athene-v2": {
    "Tag / filename": "athene-v2",
    "Sizes / variants": "72b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "72B model focused on coding/math/logs.",
    "How to pull (example)": "ollama pull athene-v2:72b"
  },
  "nemotron": {
    "Tag / filename": "nemotron",
    "Sizes / variants": "70b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "NVIDIA fine‑tuned Llama‑3.1‑70B.",
    "How to pull (example)": "ollama pull nemotron:70b"
  },
  "nemotron-mini": {
    "Tag / filename": "nemotron-mini",
    "Sizes / variants": "4b",
    "Supports Tools": "Yes",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Small commercial‑friendly model.",
    "How to pull (example)": "ollama pull nemotron-mini:4b"
  },
  "llama4": {
    "Tag / filename": "llama4",
    "Sizes / variants": "16x17b, 128x17b (MoE)",
    "Supports Tools": "Yes",
    "Supports Vision": "Yes",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Meta's natively multimodal models.",
    "How to pull (example)": "ollama pull llama4:16x17b"
  },
  "gemma3": {
    "Tag / filename": "gemma3",
    "Sizes / variants": "270m, 1b, 4b, 12b, 27b",
    "Supports Tools": "(not tagged)",
    "Supports Vision": "Yes",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "128K",
    "Example disk size (latest)": "",
    "Notes": "Google Gemma 3 multimodal.",
    "How to pull (example)": "ollama pull gemma3:4b"
  },
  "llava": {
    "Tag / filename": "llava",
    "Sizes / variants": "7b, 13b, 34b (v1.6)",
    "Supports Tools": "No",
    "Supports Vision": "Yes",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "LLaVA vision‑language model.",
    "How to pull (example)": "ollama pull llava:13b"
  },
  "llava-llama3": {
    "Tag / filename": "llava-llama3",
    "Sizes / variants": "8b",
    "Supports Tools": "No",
    "Supports Vision": "Yes",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "LLaVA on Llama 3 Instruct.",
    "How to pull (example)": "ollama pull llava-llama3:8b"
  },
  "llava-phi3": {
    "Tag / filename": "llava-phi3",
    "Sizes / variants": "3.8b",
    "Supports Tools": "No",
    "Supports Vision": "Yes",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Small LLaVA fine‑tune from Phi‑3 Mini.",
    "How to pull (example)": "ollama pull llava-phi3"
  },
  "qwen2.5vl": {
    "Tag / filename": "qwen2.5vl",
    "Sizes / variants": "3b, 7b, 32b, 72b",
    "Supports Tools": "No (vision tag)",
    "Supports Vision": "Yes",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Qwen flagship VLM.",
    "How to pull (example)": "ollama pull qwen2.5vl:7b"
  },
  "llama3.2-vision": {
    "Tag / filename": "llama3.2-vision",
    "Sizes / variants": "11b, 90b",
    "Supports Tools": "No (vision tag)",
    "Supports Vision": "Yes",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Llama 3.2 vision reasoning models.",
    "How to pull (example)": "ollama pull llama3.2-vision:11b"
  },
  "minicpm-v": {
    "Tag / filename": "minicpm-v",
    "Sizes / variants": "8b",
    "Supports Tools": "No",
    "Supports Vision": "Yes",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Multimodal LLM series.",
    "How to pull (example)": "ollama pull minicpm-v:8b"
  },
  "moondream": {
    "Tag / filename": "moondream",
    "Sizes / variants": "1.8b",
    "Supports Tools": "No",
    "Supports Vision": "Yes",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Small VLM for edge devices.",
    "How to pull (example)": "ollama pull moondream:1.8b"
  },
  "bakllava": {
    "Tag / filename": "bakllava",
    "Sizes / variants": "7b",
    "Supports Tools": "No",
    "Supports Vision": "Yes",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Mistral 7B + LLaVA arch.",
    "How to pull (example)": "ollama pull bakllava:7b"
  },
  "nomic-embed-text": {
    "Tag / filename": "nomic-embed-text",
    "Sizes / variants": "-",
    "Supports Tools": "No",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "Yes",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "General text embeddings.",
    "How to pull (example)": "ollama pull nomic-embed-text"
  },
  "mxbai-embed-large": {
    "Tag / filename": "mxbai-embed-large",
    "Sizes / variants": "335m",
    "Supports Tools": "No",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "Yes",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Mixedbread large embeddings.",
    "How to pull (example)": "ollama pull mxbai-embed-large"
  },
  "bge-m3": {
    "Tag / filename": "bge-m3",
    "Sizes / variants": "567m",
    "Supports Tools": "No",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "Yes",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "BAAI multilingual/functional embeddings.",
    "How to pull (example)": "ollama pull bge-m3"
  },
  "all-minilm": {
    "Tag / filename": "all-minilm",
    "Sizes / variants": "22m, 33m",
    "Supports Tools": "No",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "Yes",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Sentence-transformers MiniLM family.",
    "How to pull (example)": "ollama pull all-minilm"
  },
  "snowflake-arctic-embed": {
    "Tag / filename": "snowflake-arctic-embed",
    "Sizes / variants": "22m, 33m, 110m, 137m, 335m",
    "Supports Tools": "No",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "Yes",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Snowflake Arctic embeddings.",
    "How to pull (example)": "ollama pull snowflake-arctic-embed"
  },
  "snowflake-arctic-embed2": {
    "Tag / filename": "snowflake-arctic-embed2",
    "Sizes / variants": "568m",
    "Supports Tools": "No",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "Yes",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Arctic Embed 2.0 (multilingual).",
    "How to pull (example)": "ollama pull snowflake-arctic-embed2"
  },
  "granite-embedding": {
    "Tag / filename": "granite-embedding",
    "Sizes / variants": "30m, 278m",
    "Supports Tools": "No",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "Yes",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "IBM Granite embedding models.",
    "How to pull (example)": "ollama pull granite-embedding"
  },
  "codellama": {
    "Tag / filename": "codellama",
    "Sizes / variants": "7b, 13b, 34b, 70b",
    "Supports Tools": "No",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "varies (e.g., 13GB for 22B Codestral)",
    "Notes": "Meta Code Llama family.",
    "How to pull (example)": "ollama pull codellama:13b"
  },
  "codegemma": {
    "Tag / filename": "codegemma",
    "Sizes / variants": "2b, 7b (code / instruct / fill‑in‑middle)",
    "Supports Tools": "No",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Google CodeGemma.",
    "How to pull (example)": "ollama pull codegemma:7b"
  },
  "codestral": {
    "Tag / filename": "codestral",
    "Sizes / variants": "22b",
    "Supports Tools": "No",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "32K",
    "Example disk size (latest)": "13GB (Q4)",
    "Notes": "Mistral code model.",
    "How to pull (example)": "ollama pull codestral"
  },
  "deepseek-coder": {
    "Tag / filename": "deepseek-coder",
    "Sizes / variants": "1.3b, 6.7b, 33b",
    "Supports Tools": "No",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "DeepSeek code models.",
    "How to pull (example)": "ollama pull deepseek-coder:6.7b"
  },
  "llama2": {
    "Tag / filename": "llama2",
    "Sizes / variants": "7b, 13b, 70b",
    "Supports Tools": "No",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Meta Llama 2 family.",
    "How to pull (example)": "ollama pull llama2:13b"
  },
  "orca2": {
    "Tag / filename": "orca2",
    "Sizes / variants": "7b, 13b",
    "Supports Tools": "No",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Microsoft Orca 2 (reasoning‑tuned on Llama 2).",
    "How to pull (example)": "ollama pull orca2"
  },
  "llama-guard3": {
    "Tag / filename": "llama-guard3",
    "Sizes / variants": "1b, 8b",
    "Supports Tools": "No",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Safety classification (guardrails).",
    "How to pull (example)": "ollama pull llama-guard3"
  },
  "reader-lm": {
    "Tag / filename": "reader-lm",
    "Sizes / variants": "0.5b, 1.5b",
    "Supports Tools": "No",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "HTML→Markdown conversion model.",
    "How to pull (example)": "ollama pull reader-lm"
  },
  "deepseek-v3": {
    "Tag / filename": "deepseek-v3",
    "Sizes / variants": "671b (MoE, ~37b active)",
    "Supports Tools": "No (not tagged)",
    "Supports Vision": "No",
    "Supports Thinking": "No",
    "Embedding": "No",
    "Context (if stated)": "",
    "Example disk size (latest)": "",
    "Notes": "Strong MoE language model.",
    "How to pull (example)": "ollama pull deepseek-v3"
  }
}